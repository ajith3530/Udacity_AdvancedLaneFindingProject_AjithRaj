{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Importing all the required modules '''\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calibration_function():\n",
    "    '''Detects distortion cofficients by analysing few test images from the source camera. These Distortion coefficients \n",
    "    are used to undistort new input images to the software pipeline. The Camera Calibration should be performed\n",
    "    only once before start of final execution.'''\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('Calibration_Data/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    ############ Using the Calibration Parameters for Distortion Correction\n",
    "    img      = cv2.imread('Calibration_Data/test1.jpg', cv2.IMREAD_COLOR)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "        \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageTransformation_function(main_image):\n",
    "    '''Processing the input image to detect the main object of interest and highlights the detected objects in the final output\n",
    "    A color space based transformation function is used over Canny or Sobel due to the high robustness in detection accuracy\n",
    "    under stress conditions like low lighting, noise ratio, etc.\n",
    "    '''\n",
    "    ############ LAB Image Processing -- Yellow Lanes\n",
    "    lab_image    = cv2.cvtColor(main_image , cv2.COLOR_RGB2LAB)\n",
    "    L,A,B=cv2.split(lab_image)\n",
    "    B_image = B\n",
    "    ret,whitelane_image = cv2.threshold(B_image,160,200,cv2.THRESH_BINARY)\n",
    "   \n",
    "    ############# RGB Image Processing -- White Lanes   \n",
    "    lower = np.array([225,180,200],dtype = \"uint8\")\n",
    "    upper = np.array([255, 255, 255],dtype = \"uint8\")\n",
    "    mask = cv2.inRange(main_image , lower, upper)\n",
    "    S = cv2.bitwise_and(main_image, main_image, mask = mask)\n",
    "    S = cv2.cvtColor(S, cv2.COLOR_RGB2GRAY)\n",
    "    yellowlane_image = S\n",
    "    ret,S_binary = cv2.threshold(yellowlane_image,160,200,cv2.THRESH_BINARY)\n",
    "    \n",
    "    ############ Combining HLS and LAB outputs\n",
    "    combined_image =  cv2.bitwise_or(yellowlane_image,whitelane_image)\n",
    "    \n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerspectiveTransform_function(img):\n",
    "    '''Takes the input image and creates a bird's eye view of the image with only the main object of interest in the scope. ''' \n",
    "    offset = 100 # offset for dst points\n",
    "    \n",
    "    # Grab the image shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    leftupperpoint  = [568,470]\n",
    "    rightupperpoint = [717,470]\n",
    "    leftlowerpoint  = [260,680]\n",
    "    rightlowerpoint = [1043,680]\n",
    "\n",
    "    src = np.float32([leftupperpoint, leftlowerpoint, rightupperpoint, rightlowerpoint])\n",
    "    dst = np.float32([[200,0], [200,680], [1000,0], [1000,680]])\n",
    "\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)\n",
    "   \n",
    "    return warped, M, M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Directsearch_function(binary_warped):\n",
    "    '''Directly searches for the Lane markings without considering the previous observations, and returns the location of the\n",
    "    lane markings on the current image. This is a more calculation intensive function.'''\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 10\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 80 \n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low       = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high      = binary_warped.shape[0] - window*window_height\n",
    "\n",
    "        win_xleft_low   = leftx_current  - margin\n",
    "        win_xleft_high  = leftx_current  + margin\n",
    "        win_xright_low  = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        \n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        print(\"Value Error Received\")\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Indirectsearch_function(binary_warped,left_fit,right_fit):\n",
    "    '''Based on the previous observations, searches for the lane markings near the previous lane points. This function is less\n",
    "    calculation intensive. '''\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    margin = 100\n",
    "    \n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]    \n",
    "    \n",
    "    return leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SanityCheck_function(left_fit,right_fit):\n",
    "    '''Checks whether tha lane detection by Indirect/Direct conditions were successfull.'''\n",
    "    #Status = True  --> Valid Line\n",
    "    #Status = False --> Invalid Line\n",
    "    status = True\n",
    "    try:\n",
    "        if len(left_fit) ==0 or len(right_fit) == 0:\n",
    "            status = False\n",
    "    except TypeError:\n",
    "        status = False\n",
    "        \n",
    "    return status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaneAproximation_function(binary_warped, LaneEquations, Sanity_status):\n",
    "    '''Calls Direct/Indirect Search functions to find lanes in the input image. The selection of the Direct/Indirect function\n",
    "    depends on SanityCheck status from the previous detection results'''\n",
    "    if(not Sanity_status):\n",
    "        leftx, lefty, rightx, righty = Directsearch_function(binary_warped)\n",
    "    else:\n",
    "        leftx, lefty, rightx, righty = Indirectsearch_function(binary_warped, LaneEquations[2], LaneEquations[3])\n",
    "        \n",
    "        try:\n",
    "            left_fit  = np.polyfit(lefty, leftx, 2)\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "            Sanity_status =  SanityCheck_function(left_fit,right_fit) \n",
    "            \n",
    "            if(not Sanity_status):\n",
    "                leftx, lefty, rightx, righty = Directsearch_function(binary_warped)\n",
    "                \n",
    "        except TypeError:\n",
    "            \n",
    "            #Using Previous Values\n",
    "            left_fit  = LaneEquations[2] \n",
    "            right_fit = LaneEquations[3]    \n",
    "    \n",
    "    out_img = np.dstack((binary_warped,binary_warped,binary_warped))\n",
    "    \n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    try:\n",
    "        left_fit  = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    except TypeError:\n",
    "        #Using Previous Values\n",
    "        left_fit  = LaneEquations[2] \n",
    "        right_fit = LaneEquations[3]\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx  = left_fit[0] *ploty**2 + left_fit[1] *ploty +  left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx]   = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]    \n",
    "\n",
    "    Sanity_status =  SanityCheck_function(left_fit,right_fit) \n",
    "\n",
    "    return out_img, [left_fitx, right_fitx, left_fit, right_fit], Sanity_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_curvature(binary_warped, left_fit, right_fit):\n",
    "    '''Calculates the Right/Left Curvature and Vehicle offset based on the lane detection results.'''\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    Left_CurvatureRadius  =  ((1 + (2*left_fit_cr[0] *y_eval*ym_per_pix + left_fit_cr[1])**2) **1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    Right_CurvatureRadius = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Calculate vehicle center\n",
    "    #left_lane and right lane bottom in pixels\n",
    "    Left_LaneBottom = (left_fit[0]*y_eval)**2 + left_fit[0]*y_eval + left_fit[2]\n",
    "    Right_LaneBottom = (right_fit[0]*y_eval)**2 + right_fit[0]*y_eval + right_fit[2]\n",
    "    \n",
    "    # Lane center as mid of left and right lane bottom                        \n",
    "    lane_center = (Left_LaneBottom + Right_LaneBottom)/2.\n",
    "    center_image = 640\n",
    "    center = (lane_center - center_image)*xm_per_pix #Convert to meters\n",
    "    position = \"left\" if center < 0 else \"right\"\n",
    "    center = \"Vehicle is {:.2f}m {}\".format(center, position)\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    return Left_CurvatureRadius, Right_CurvatureRadius, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_on_image(undist, warped_img, left_fit, right_fit, Minv, left_curvature, right_curvature, center):\n",
    "    '''Takes all the detection parameters like Lane markings and curvation/offset details calculated from the helper functions\n",
    "    and overlays it over each input frame'''\n",
    "    ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255,0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undist.shape[1], undist.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    cv2.putText(result, 'Left curvature: {:.0f} m'.format(left_curvature), (50, 50), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(result, 'Right curvature: {:.0f} m'.format(right_curvature), (50, 100), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(result, '{}'.format(center), (50, 150), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 225/226 [00:35<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "CPU times: user 16.5 s, sys: 369 ms, total: 16.9 s\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "'''All the Helper functions are invoked using a callable class which initializes once to calculate the calibration parameters,\n",
    "then subsequently runs the call section which runs on each input frame.'''\n",
    "class DetectionPipeline:\n",
    "    def __init__(self):\n",
    "        self.mtx , self.dist = Calibration_function()\n",
    "        #LaneSearch_flag = True  --> Direct Lane Search\n",
    "        #LaneSearch_flag = False --> InDirect Lane Search\n",
    "        self.Sanity_status = False\n",
    "        self.LaneEquations = None\n",
    "               \n",
    "    def __call__(self, main_image):\n",
    "        UndistortedImage   = cv2.undistort(main_image, self.mtx, self.dist, None, self.mtx)   \n",
    "        Transformed_Image  = ImageTransformation_function(UndistortedImage)\n",
    "        Birdseye_Image, M, M_inv   = PerspectiveTransform_function(Transformed_Image)\n",
    "        Lane_Image, self.LaneEquations, self.Sanity_status  = LaneAproximation_function(Birdseye_Image, self.LaneEquations, self.Sanity_status)\n",
    "        Left_curve, Right_curve, Lane_Center = radius_curvature(Lane_Image, self.LaneEquations[2], self.LaneEquations[3])\n",
    "        Final_Ouput = draw_on_image(UndistortedImage, Birdseye_Image, self.LaneEquations[2], self.LaneEquations[3], M_inv, Left_curve, Right_curve, Lane_Center)\n",
    "        \n",
    "        return Final_Ouput\n",
    "\n",
    "'''Module Acceptance Test Case'''\n",
    "#image = cv2.imread('Test_Images/test1.jpg')\n",
    "#class_image    = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "DetectionPipeline_Instance = DetectionPipeline()\n",
    "#plt.imshow(DetectionPipeline_Instance(class_image))\n",
    "\n",
    "#Running Software Pipeline on a Video Stream\n",
    "white_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"Test_Videos/project_video.mp4\").subclip(1,10)\n",
    "white_clip = clip1.fl_image(DetectionPipeline_Instance)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
